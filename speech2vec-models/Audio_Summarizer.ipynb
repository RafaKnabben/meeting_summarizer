{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Summarizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcgzYo_pkhFw"
      },
      "source": [
        "!pip install deepspeech\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/audio-0.9.3.tar.gz\n",
        "!tar xvf audio-0.9.3.tar.gz\n",
        "!ls -l ./audio/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky0GQT7Gnxit"
      },
      "source": [
        "! pip install youtube_dl\n",
        "! pip install pydub\n",
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "! pip install punctuator\n",
        "! pip install SpeechRecognition\n",
        "\n",
        "! apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
        "! pip install Cython\n",
        "! pip install bert-extractive-summarizer\n",
        "! pip install nemo_toolkit[all]\n",
        "! pip install pynini\n",
        "! pip install rake_nltk\n",
        "! pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiwChdPynIHC"
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "from pydub import AudioSegment\n",
        "from deepspeech import Model\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "import contextlib\n",
        "import wave\n",
        "from nemo.collections.nlp.models import PunctuationCapitalizationModel\n",
        "import torchvision\n",
        "from summarizer import Summarizer\n",
        "import nltk\n",
        "from rake_nltk import Rake\n",
        "import speech_recognition as sr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcnXf6vQWnIz"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us7k-_yqkGco"
      },
      "source": [
        "def make_transcript(audio_file):\n",
        "    model_file_path = \"/content/deepspeech-0.9.3-models.pbmm\"\n",
        "    lm_file_path = \"/content/deepspeech-0.9.3-models.scorer\"\n",
        "    beam_width = 100\n",
        "    lm_alpha = 0.93\n",
        "    lm_beta = 1.18\n",
        "\n",
        "    model = Model(model_file_path)\n",
        "    model.enableExternalScorer(lm_file_path)\n",
        "\n",
        "    model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "    model.setBeamWidth(beam_width)\n",
        "\n",
        "    rate, buffer= wav_read(audio_file)\n",
        "    return model.stt(buffer)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMmMf2CBXQSL"
      },
      "source": [
        "def capital_letters(text):\n",
        "    capitalized = \"\"\n",
        "    if text[0] != text[0].capitalize():\n",
        "        capitalized = capitalized + text[0].capitalize()\n",
        "        text = text[1:]\n",
        "\n",
        "    for num in range(len(text)):\n",
        "        if text[num - 2] + text[num - 1] != \". \":\n",
        "            capitalized = capitalized + text[num]\n",
        "        if text[num - 2] + text[num - 1] == \". \":\n",
        "            capitalized = capitalized + text[num].capitalize()\n",
        "\n",
        "    return capitalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3MbDfkIoh7z"
      },
      "source": [
        "def set_punctuation(transcript):\n",
        "    PunctuationCapitalizationModel.list_available_models()\n",
        "    model = PunctuationCapitalizationModel.from_pretrained(\"punctuation_en_bert\")\n",
        "    punct_transcript = model.add_punctuation_capitalization([transcript])\n",
        "    punct_transcript = punct_transcript[0]\n",
        "\n",
        "    return punct_transcript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7CvVCdnjdB"
      },
      "source": [
        "def get_tube(url):\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(url, download=False)\n",
        "        video_id = info_dict.get('id', None)\n",
        "        video_title = info_dict.get('title', None)\n",
        "        video_duration = info_dict.get('duration', None)\n",
        "\n",
        "    min = int(video_duration / 60)\n",
        "    sec = video_duration % 60\n",
        "    if sec < 10:\n",
        "      duration = f\"{min}:0{sec}\"\n",
        "    else:\n",
        "      duration = f\"{min}:{sec}\"\n",
        "    \n",
        "    video_info = {}\n",
        "    video_info[\"path\"] = f'{video_id}.mp3'\n",
        "    video_info[\"title\"] = video_title\n",
        "    video_info[\"duration\"] = duration\n",
        "\n",
        "    ydl_opts.update({'outtmpl':video_info[\"path\"]})\n",
        "\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "        \n",
        "    return video_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy1eg6hzn5qW"
      },
      "source": [
        "def get_transcript(url):\n",
        "    video_info = get_tube(url)\n",
        "    path = video_info[\"path\"]\n",
        "    path_audio =  f\"/content/{path}\"\n",
        "    shortcut = path_audio[:-4]\n",
        "    path_wav = f\"{shortcut}.wav\"\n",
        "\n",
        "    sound = AudioSegment.from_file(path_audio)\n",
        "    sound.export(path_wav, format=\"wav\")\n",
        "\n",
        "    #os.remove(path_audio) \n",
        "\n",
        "    audio, sr = librosa.load(path_wav, sr=16000)\n",
        "    soundfile.write(path_wav, data = audio, samplerate = sr)\n",
        "    \n",
        "    transcript = make_transcript(path_wav)\n",
        "    #transcript = set_punctuation(transcript)\n",
        "    video_info[\"transcript\"] = transcript\n",
        "\n",
        "    #os.remove(path_wav)\n",
        "\n",
        "    return video_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBhP5Gq_ZBoC"
      },
      "source": [
        "def keywords(transcript):\n",
        "  rake_nltk_var = Rake()\n",
        "  rake_nltk_var.extract_keywords_from_text(transcript)\n",
        "  key_output = rake_nltk_var.get_ranked_phrases()\n",
        "  #keyword_extracted = rake_nltk_var.get_ranked_phrases_with_scores()\n",
        "\n",
        "  return key_output[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwIBObkdoECf"
      },
      "source": [
        "def abstract_summary(transcript):\n",
        "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    tokenized_text = tokenizer.encode(transcript, return_tensors=\"pt\").to(device)\n",
        "    summary_ids = model.generate(tokenized_text,\n",
        "                                      num_beams=4,\n",
        "                                      no_repeat_ngram_size=2,\n",
        "                                      min_length=50,\n",
        "                                      max_length=300,\n",
        "                                      early_stopping=True)\n",
        "\n",
        "    abs_output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    abs_output = capital_letters(abs_output)\n",
        "\n",
        "    return abs_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EyS5zyTJ-LF"
      },
      "source": [
        "def extractive_summary(transcript):\n",
        "    model = Summarizer()\n",
        "    result = model(transcript, min_length=50)\n",
        "    ext_output = \"\".join(result)\n",
        "    ext_output = capital_letters(ext_output)\n",
        "\n",
        "    return ext_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3K1QKVAcGFQ"
      },
      "source": [
        "def assembling_url(url):\n",
        "  video_info = get_transcript(url)\n",
        "  transcript = video_info[\"transcript\"]\n",
        "  video_title = video_info[\"title\"]\n",
        "  video_duration = video_info[\"duration\"]\n",
        "\n",
        "  key_output = keywords(transcript)\n",
        "  abs_output = abstract_summary(transcript)\n",
        "  ext_output = extractive_summary(transcript)\n",
        "\n",
        "  return video_info, abs_output, ext_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNqgHEZXRs21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "4bcc9ff1-dea1-40e6-eb63-9dac9ef3f24d"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "video_info, abs, ext = assembling_url(\"https://www.youtube.com/watch?v=oaTssshwmwo\")\n",
        "end = time.time()\n",
        "\n",
        "length = int(end - start)\n",
        "min = int(length / 60)\n",
        "sec = length % 60\n",
        "if sec < 10:\n",
        "  duration = f\"{min}:0{sec}\"\n",
        "else:\n",
        "  duration = f\"{min}:{sec}\"\n",
        "\n",
        "print(duration)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3708db6cdecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvideo_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembling_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.youtube.com/watch?v=oaTssshwmwo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'assembling_url' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "tMAG4f_EM4zI",
        "outputId": "b3e21094-1c93-4141-8e46-c278d5806851"
      },
      "source": [
        "video_info['transcript']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'intelligence is really techniques that help machines and computers mimic human behavior is the device being smart how it becomes smart under the hood is the next layer of machine learning which are the general techniques or variety of techniques device smart'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "6UwIcBmBM9Xe",
        "outputId": "6daaea1b-a6d0-4676-dab1-d98b2148d4a2"
      },
      "source": [
        "abs\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Artificial artificial artificial becoming smart is really techniques that help machines mimic human behavior is the device being smart how it becomes smart under the next layer of machine learning is artificial artificial artificial artificial artificial devices becoming devices become smart devices being intelligent is actually techniques and techniques the devices smart is smart is smart. Smart. Device smart...... Machine learning or artificial.. The next level of artificial intelligence is machine. Artificial. So'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LTPKYtTVNBDh",
        "outputId": "765ebbe4-ed98-441a-aea6-fdc43ecc1030"
      },
      "source": [
        "ext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"D'artifice licence is really techniques that help machines and computers mimic human behavior, Pitious nesting. Artificial intelligence is going to be used in everything To give you two examples. Otonabee of any kind are not going to be autonomous without artificial intelligence in the medical field.\""
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyCRyPIWHxdy"
      },
      "source": [
        "#get_transcript(\"https://www.youtube.com/watch?v=lh4d1fjzfNA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PPFmiWELOTU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}