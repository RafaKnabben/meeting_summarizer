{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcgzYo_pkhFw"
      },
      "outputs": [],
      "source": [
        "!pip install deepspeech\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/audio-0.9.3.tar.gz\n",
        "!tar xvf audio-0.9.3.tar.gz\n",
        "!ls -l ./audio/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky0GQT7Gnxit"
      },
      "outputs": [],
      "source": [
        "! pip install youtube_dl\n",
        "! pip install pydub\n",
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "! pip install punctuator\n",
        "! pip install SpeechRecognition\n",
        "\n",
        "! apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
        "! pip install Cython\n",
        "! pip install bert-extractive-summarizer\n",
        "! pip install nemo_toolkit[all]\n",
        "! pip install pynini\n",
        "! pip install rake_nltk\n",
        "! pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiwChdPynIHC"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "from pydub import AudioSegment\n",
        "from deepspeech import Model\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "import contextlib\n",
        "import wave\n",
        "from nemo.collections.nlp.models import PunctuationCapitalizationModel\n",
        "import torchvision\n",
        "from summarizer import Summarizer\n",
        "import nltk\n",
        "from rake_nltk import Rake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcnXf6vQWnIz"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Us7k-_yqkGco"
      },
      "outputs": [],
      "source": [
        "def make_transcript(audio_file):\n",
        "    model_file_path = \"/content/deepspeech-0.9.3-models.pbmm\"\n",
        "    lm_file_path = \"/content/deepspeech-0.9.3-models.scorer\"\n",
        "    beam_width = 100\n",
        "    lm_alpha = 0.93\n",
        "    lm_beta = 1.18\n",
        "\n",
        "    model = Model(model_file_path)\n",
        "    model.enableExternalScorer(lm_file_path)\n",
        "\n",
        "    model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "    model.setBeamWidth(beam_width)\n",
        "\n",
        "    rate, buffer= wav_read(audio_file)\n",
        "    return model.stt(buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LMmMf2CBXQSL"
      },
      "outputs": [],
      "source": [
        "def capital_letters(text):\n",
        "    capitalized = \"\"\n",
        "    if text[0] != text[0].capitalize():\n",
        "        capitalized = capitalized + text[0].capitalize()\n",
        "        text = text[1:]\n",
        "\n",
        "    for num in range(len(text)):\n",
        "        if text[num - 2] + text[num - 1] != \". \":\n",
        "            capitalized = capitalized + text[num]\n",
        "        if text[num - 2] + text[num - 1] == \". \":\n",
        "            capitalized = capitalized + text[num].capitalize()\n",
        "\n",
        "    return capitalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T3MbDfkIoh7z"
      },
      "outputs": [],
      "source": [
        "def set_punctuation(transcript):\n",
        "    PunctuationCapitalizationModel.list_available_models()\n",
        "    model = PunctuationCapitalizationModel.from_pretrained(\"punctuation_en_bert\")\n",
        "    punct_transcript = model.add_punctuation_capitalization([transcript])\n",
        "    punct_transcript = punct_transcript[0]\n",
        "\n",
        "    return punct_transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nw7CvVCdnjdB"
      },
      "outputs": [],
      "source": [
        "def get_tube(url):\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(url, download=False)\n",
        "        video_id = info_dict.get('id', None)\n",
        "        video_title = info_dict.get('title', None)\n",
        "        video_duration = info_dict.get('duration', None)\n",
        "\n",
        "    min = int(video_duration / 60)\n",
        "    sec = video_duration % 60\n",
        "    if sec < 10:\n",
        "      duration = f\"{min}:0{sec}\"\n",
        "    else:\n",
        "      duration = f\"{min}:{sec}\"\n",
        "    \n",
        "    video_info = {}\n",
        "    video_info[\"path\"] = f'{video_id}.mp3'\n",
        "    video_info[\"title\"] = video_title\n",
        "    video_info[\"duration\"] = duration\n",
        "\n",
        "    ydl_opts.update({'outtmpl':video_info[\"path\"]})\n",
        "\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "        \n",
        "    return video_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zy1eg6hzn5qW"
      },
      "outputs": [],
      "source": [
        "def get_transcript(url):\n",
        "    video_info = get_tube(url)\n",
        "    path = video_info[\"path\"]\n",
        "    path_audio =  f\"/content/{path}\"\n",
        "    shortcut = path_audio[:-4]\n",
        "    path_wav = f\"{shortcut}.wav\"\n",
        "\n",
        "    sound = AudioSegment.from_file(path_audio)\n",
        "    sound.export(path_wav, format=\"wav\")\n",
        "\n",
        "    #os.remove(path_audio) \n",
        "\n",
        "    audio, sr = librosa.load(path_wav, sr=16000)\n",
        "    soundfile.write(path_wav, data = audio, samplerate = sr)\n",
        "    \n",
        "    transcript = make_transcript(path_wav)\n",
        "    transcript = set_punctuation(transcript)\n",
        "    video_info[\"transcript\"] = transcript\n",
        "\n",
        "    #os.remove(path_wav)\n",
        "\n",
        "    return video_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KBhP5Gq_ZBoC"
      },
      "outputs": [],
      "source": [
        "def keywords(transcript):\n",
        "  rake_nltk_var = Rake()\n",
        "  rake_nltk_var.extract_keywords_from_text(transcript)\n",
        "  key_output = rake_nltk_var.get_ranked_phrases()\n",
        "  #keyword_extracted = rake_nltk_var.get_ranked_phrases_with_scores()\n",
        "\n",
        "  return key_output[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gwIBObkdoECf"
      },
      "outputs": [],
      "source": [
        "def abstract_summary(transcript):\n",
        "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    tokenized_text = tokenizer.encode(transcript, return_tensors=\"pt\").to(device)\n",
        "    summary_ids = model.generate(tokenized_text,\n",
        "                                      num_beams=4,\n",
        "                                      no_repeat_ngram_size=2,\n",
        "                                      min_length=50,\n",
        "                                      max_length=125,\n",
        "                                      early_stopping=True)\n",
        "\n",
        "    abs_output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    abs_output = capital_letters(abs_output)\n",
        "\n",
        "    return abs_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1EyS5zyTJ-LF"
      },
      "outputs": [],
      "source": [
        "def extractive_summary(transcript):\n",
        "    model = Summarizer()\n",
        "    result = model(transcript, min_length=50)\n",
        "    ext_output = \"\".join(result)\n",
        "    ext_output = capital_letters(ext_output)\n",
        "\n",
        "    return ext_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o3K1QKVAcGFQ"
      },
      "outputs": [],
      "source": [
        "def assembling_url(url):\n",
        "  video_info = get_transcript(url)\n",
        "  transcript = video_info[\"transcript\"]\n",
        "  video_title = video_info[\"title\"]\n",
        "  video_duration = video_info[\"duration\"]\n",
        "\n",
        "  key_output = keywords(transcript)\n",
        "  abs_output = abstract_summary(transcript)\n",
        "  ext_output = extractive_summary(transcript)\n",
        "\n",
        "  return video_info, abs_output, ext_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"HAHAHA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNqgHEZXRs21",
        "outputId": "47755a7a-1323-4203-a3f4-682f08ccda6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] FhwNbG9HLhU: Downloading webpage\n",
            "[youtube] FhwNbG9HLhU: Downloading webpage\n",
            "[download] FhwNbG9HLhU.mp3 has already been downloaded\n",
            "[download] 100% of 2.09MiB\n",
            "[ffmpeg] Correcting container in \"FhwNbG9HLhU.mp3\"\n",
            "[ffmpeg] Post-process file FhwNbG9HLhU.mp3 exists, skipping\n",
            "[NeMo I 2021-11-30 12:12:29 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.5.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
            "[NeMo I 2021-11-30 12:12:29 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.5.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo\n",
            "[NeMo I 2021-11-30 12:12:29 common:728] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2021-11-30 12:12:34 tokenizer_utils:123] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmp02m7xbl5/tokenizer.vocab_file, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using eos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "[NeMo W 2021-11-30 12:12:35 modelPT:131] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    text_file: text_train.txt\n",
            "    labels_file: labels_train.txt\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    batch_size: 64\n",
            "    \n",
            "[NeMo W 2021-11-30 12:12:35 modelPT:138] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    ds_item: null\n",
            "    text_file: text_dev.txt\n",
            "    labels_file: labels_dev.txt\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    batch_size: 64\n",
            "    \n",
            "[NeMo W 2021-11-30 12:12:35 modelPT:144] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    ds_item: null\n",
            "    text_file: text_dev.txt\n",
            "    labels_file: labels_dev.txt\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    batch_size: 64\n",
            "    \n",
            "[NeMo W 2021-11-30 12:12:35 nlp_overrides:174] Apex was not found. Using model parallel or megatron models will error out.\n",
            "[NeMo W 2021-11-30 12:12:35 modelPT:1079] World size can only be set by PyTorch Lightning Trainer.\n",
            "[NeMo W 2021-11-30 12:12:35 modelPT:198] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2021-11-30 12:12:40 save_restore_connector:149] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.5.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
            "[NeMo I 2021-11-30 12:12:40 punctuation_capitalization_model:577] Using batch size 1 for inference\n",
            "[NeMo I 2021-11-30 12:12:40 punctuation_capitalization_dataset:543] Max length: 64\n",
            "[NeMo I 2021-11-30 12:12:40 data_preprocessing:358] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2021-11-30 12:12:40 data_preprocessing:364] Min: 282 |                  Max: 282 |                  Mean: 282.0 |                  Median: 282.0\n",
            "[NeMo I 2021-11-30 12:12:40 data_preprocessing:366] 75 percentile: 282.00\n",
            "[NeMo I 2021-11-30 12:12:40 data_preprocessing:367] 99 percentile: 282.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [00:09<00:00,  3.20batch/s]\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Two men die as Storm Arwen brings 98mph gusts to UK - BBC News\n",
            "Length: 2:16\n",
            "\n",
            "Keywords: ['sureties filmed treacherous conditions near edinbro', 'one hundred thousand homes without power', 'harbourage seventy four thousand customers', 'twenty louis got stackin snow', 'storm cost damage across scotland']\n",
            "\n",
            "Abstract Summary: A Major disruption across the north east of the country, with more than one hundred thousand homes without power. The Met Office issued red weather warnings, meaning there was an potential risk to life. A harbourage seventy four thousand customers, and the bad weather also affected its I missile, which had to be reread to yellow, where the warning to high winds across central England, Scotland, Wales and Norton Island, remains in place until six o'clock the evening Emily una be seen us.\n",
            "\n",
            "Extractive Summary: A storm await parts of the out with high winds, rain and snow. Their further, whether warnings across the Kodak as Emlenton, winds of more than ninety miles an hour took Pomeloes, Scotland.\n",
            "2:56\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "assembling_url(\"https://www.youtube.com/watch?v=FhwNbG9HLhU\")\n",
        "end = time.time()\n",
        "\n",
        "length = int(end - start)\n",
        "min = int(length / 60)\n",
        "sec = length % 60\n",
        "if sec < 10:\n",
        "  duration = f\"{min}:0{sec}\"\n",
        "else:\n",
        "  duration = f\"{min}:{sec}\"\n",
        "\n",
        "print(duration)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Audio_Summarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
