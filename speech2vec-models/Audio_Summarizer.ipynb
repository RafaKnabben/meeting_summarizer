{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Summarizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcgzYo_pkhFw"
      },
      "source": [
        "!pip install deepspeech\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/audio-0.9.3.tar.gz\n",
        "!tar xvf audio-0.9.3.tar.gz\n",
        "!ls -l ./audio/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgxgakpUT8XZ"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLlNFtbLUBl8"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky0GQT7Gnxit"
      },
      "source": [
        "! pip install youtube_dl\n",
        "! pip install pydub\n",
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "! pip install punctuator\n",
        "! pip install SpeechRecognition\n",
        "\n",
        "! apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
        "! pip install Cython\n",
        "! pip install nemo_toolkit[all]\n",
        "! pip install pynini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiwChdPynIHC"
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "from pydub import AudioSegment\n",
        "from deepspeech import Model\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "import contextlib\n",
        "import wave\n",
        "from nemo.collections.nlp.models import PunctuationCapitalizationModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us7k-_yqkGco"
      },
      "source": [
        "def make_transcript(audio_file):\n",
        "    model_file_path = \"/content/deepspeech-0.9.3-models.pbmm\"\n",
        "    lm_file_path = \"/content/deepspeech-0.9.3-models.scorer\"\n",
        "    beam_width = 100\n",
        "    lm_alpha = 0.93\n",
        "    lm_beta = 1.18\n",
        "\n",
        "    model = Model(model_file_path)\n",
        "    model.enableExternalScorer(lm_file_path)\n",
        "\n",
        "    model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "    model.setBeamWidth(beam_width)\n",
        "\n",
        "    rate, buffer= wav_read(audio_file)\n",
        "    return model.stt(buffer)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7CvVCdnjdB"
      },
      "source": [
        "def get_tube(url):\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(url, download=False)\n",
        "        video_title = info_dict.get('id', None)\n",
        "\n",
        "    path = f'{video_title}.mp3'\n",
        "\n",
        "    ydl_opts.update({'outtmpl':path})\n",
        "\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "        \n",
        "    return path"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy1eg6hzn5qW"
      },
      "source": [
        "def get_transcript(url):\n",
        "    path =  f\"/content/{get_tube(url)}\"\n",
        "    shortcut = path[:-4]\n",
        "    path_wav = f\"{shortcut}.wav\"\n",
        "\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    sound.export(path_wav, format=\"wav\")\n",
        "\n",
        "    os.remove(path) \n",
        "\n",
        "    audio, sr = librosa.load(path_wav, sr=16000)\n",
        "    soundfile.write(path_wav, data = audio, samplerate = sr)\n",
        "    \n",
        "    transcript = make_transcript(path_wav)\n",
        "\n",
        "    os.remove(path_wav)\n",
        "\n",
        "    return transcript"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwIBObkdoECf"
      },
      "source": [
        "def transcript_summarizer(url):\n",
        "    transcript = get_transcript(url)\n",
        "\n",
        "    PunctuationCapitalizationModel.list_available_models()\n",
        "    model = PunctuationCapitalizationModel.from_pretrained(\"punctuation_en_bert\")\n",
        "    transcript = model.add_punctuation_capitalization([transcript])\n",
        "\n",
        "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "\n",
        "    t5_prepared_Text = \"summarize: \"+transcript[0]\n",
        "    tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
        "    summary_ids = model.generate(tokenized_text,\n",
        "                                      num_beams=4,\n",
        "                                      no_repeat_ngram_size=2,\n",
        "                                      min_length=30,\n",
        "                                      max_length=100,\n",
        "                                      early_stopping=True)\n",
        "\n",
        "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return print(\"\\n\\nSummarized text: \\n\",output)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UqwBh0FoIH7",
        "outputId": "f2d89e8d-7679-4bf1-da09-c4e6a80e0b98"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "transcript_summarizer(\"https://www.youtube.com/watch?v=A8SAZ8lI4m4\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] A8SAZ8lI4m4: Downloading webpage\n",
            "[youtube] A8SAZ8lI4m4: Downloading webpage\n",
            "[download] Destination: A8SAZ8lI4m4.mp3\n",
            "[download] 100% of 4.00MiB in 01:14\n",
            "[ffmpeg] Post-process file A8SAZ8lI4m4.mp3 exists, skipping\n",
            "[NeMo I 2021-11-21 23:23:36 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.5.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
            "[NeMo I 2021-11-21 23:23:36 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.5.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo\n",
            "[NeMo I 2021-11-21 23:23:36 common:728] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2021-11-21 23:23:41 tokenizer_utils:123] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpoyrzocxq/tokenizer.vocab_file, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using eos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "[NeMo W 2021-11-21 23:23:45 modelPT:131] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    text_file: text_train.txt\n",
            "    labels_file: labels_train.txt\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    batch_size: 64\n",
            "    \n",
            "[NeMo W 2021-11-21 23:23:45 modelPT:138] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    ds_item: null\n",
            "    text_file: text_dev.txt\n",
            "    labels_file: labels_dev.txt\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    batch_size: 64\n",
            "    \n",
            "[NeMo W 2021-11-21 23:23:45 modelPT:144] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    ds_item: null\n",
            "    text_file: text_dev.txt\n",
            "    labels_file: labels_dev.txt\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    batch_size: 64\n",
            "    \n",
            "[NeMo W 2021-11-21 23:23:45 nlp_overrides:174] Apex was not found. Using model parallel or megatron models will error out.\n",
            "[NeMo W 2021-11-21 23:23:45 modelPT:1079] World size can only be set by PyTorch Lightning Trainer.\n",
            "[NeMo W 2021-11-21 23:23:45 modelPT:198] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2021-11-21 23:23:52 save_restore_connector:149] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.5.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
            "[NeMo I 2021-11-21 23:23:52 punctuation_capitalization_model:577] Using batch size 1 for inference\n",
            "[NeMo I 2021-11-21 23:23:52 punctuation_capitalization_dataset:543] Max length: 64\n",
            "[NeMo I 2021-11-21 23:23:52 data_preprocessing:358] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2021-11-21 23:23:52 data_preprocessing:364] Min: 901 |                  Max: 901 |                  Mean: 901.0 |                  Median: 901.0\n",
            "[NeMo I 2021-11-21 23:23:52 data_preprocessing:366] 75 percentile: 901.00\n",
            "[NeMo I 2021-11-21 23:23:52 data_preprocessing:367] 99 percentile: 901.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [00:02<00:00, 39.15batch/s]\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Summarized text: \n",
            " aaron ramsey: Until the splitting of five, the war caused this dissolution. he says as of closing years of the Napoleonic wars, Norway was in the union, with no way Formosanta, but it was disbanded by the swedish king in 1814.\n",
            "353.48488545417786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCzFoGE-0xbG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}