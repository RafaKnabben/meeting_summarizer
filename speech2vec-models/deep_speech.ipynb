{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-speech.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuV-Mpu02gW1"
      },
      "source": [
        "## **Speech recognition model for Meeting Summarizer (alpha version)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uioWtnZk3qeJ"
      },
      "source": [
        "####**Downloading deepspeech model files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53fN3yjtJOQW",
        "outputId": "f7648d96-5a96-4522-875d-608268e52074"
      },
      "source": [
        "!pip install deepspeech\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
        "\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/audio-0.9.3.tar.gz\n",
        "!tar xvf audio-0.9.3.tar.gz\n",
        "!ls -l ./audio/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeech\n",
            "  Downloading deepspeech-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from deepspeech) (1.19.5)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.9.3\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   634  100   634    0     0   3842      0 --:--:-- --:--:-- --:--:--  3842\n",
            "100  180M  100  180M    0     0  80.6M      0  0:00:02  0:00:02 --:--:-- 96.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   667  100   667    0     0   4600      0 --:--:-- --:--:-- --:--:--  4568\n",
            "100  909M  100  909M    0     0  75.0M      0  0:00:12  0:00:12 --:--:--  183M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   655  100   655    0     0   4225      0 --:--:-- --:--:-- --:--:--  4225\n",
            "100  194k  100  194k    0     0   631k      0 --:--:-- --:--:-- --:--:--  631k\n",
            "._audio\n",
            "audio/\n",
            "audio/._2830-3980-0043.wav\n",
            "audio/2830-3980-0043.wav\n",
            "audio/._Attribution.txt\n",
            "audio/Attribution.txt\n",
            "audio/._4507-16021-0012.wav\n",
            "audio/4507-16021-0012.wav\n",
            "audio/._8455-210777-0068.wav\n",
            "audio/8455-210777-0068.wav\n",
            "audio/._License.txt\n",
            "audio/License.txt\n",
            "total 260\n",
            "-rw-r--r-- 1 501 staff 63244 Nov 18  2017 2830-3980-0043.wav\n",
            "-rw-r--r-- 1 501 staff 87564 Nov 18  2017 4507-16021-0012.wav\n",
            "-rw-r--r-- 1 501 staff 82924 Nov 18  2017 8455-210777-0068.wav\n",
            "-rw-r--r-- 1 501 staff   340 May 14  2018 Attribution.txt\n",
            "-rw-r--r-- 1 501 staff 18652 May 12  2018 License.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv2g2kPg37Ui"
      },
      "source": [
        "####**Downloading libraries and packages used below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1u2dnzGOFFC",
        "outputId": "c1eedde8-4c03-42e4-c32b-401df7edd42f"
      },
      "source": [
        "!pip install pysoundfile\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install pyaudio\n",
        "!pip install pydub\n",
        "!pip install ffmpeg-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysoundfile\n",
            "  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.7/dist-packages (from pysoundfile) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=0.6->pysoundfile) (2.20)\n",
            "Installing collected packages: pysoundfile\n",
            "Successfully installed pysoundfile-0.9.0.post1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.6).\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 184 kB of archives.\n",
            "After this operation, 891 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudiocpp0 amd64 19.6.0-1 [15.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 portaudio19-dev amd64 19.6.0-1 [104 kB]\n",
            "Fetched 184 kB in 1s (258 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.11.tar.gz (37 kB)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.11-cp37-cp37m-linux_x86_64.whl size=52601 sha256=a4bf3f46297a1322f7f288d8a6569861fd7fcfd36915b2d4f17cd4a4c37d4325\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/2e/4c/b71e7e96c861a46e6213bc6bb482b94dcf293a92c5e736c1ec\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.11\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRgN3eQU4NM0"
      },
      "source": [
        "####**Importing libraries and packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQrnmkn3RfqK"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import wave\n",
        "import librosa\n",
        "import soundfile\n",
        "import pyaudio\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "from deepspeech import Model\n",
        "from IPython.display import Audio\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr6qLU6R4p-k"
      },
      "source": [
        "####**get_transcript(): reading .wav files and getting their transcripts**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tTX5gaPUva1"
      },
      "source": [
        "def get_transcript(audio_file):\n",
        "    model_file_path = \"/content/deepspeech-0.9.3-models.pbmm\"\n",
        "    lm_file_path = \"/content/deepspeech-0.9.3-models.scorer\"\n",
        "    beam_width = 100\n",
        "    lm_alpha = 0.93\n",
        "    lm_beta = 1.18\n",
        "\n",
        "    model = Model(model_file_path)\n",
        "    model.enableExternalScorer(lm_file_path)\n",
        "\n",
        "    model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "    model.setBeamWidth(beam_width)\n",
        "\n",
        "    rate, buffer= wav_read(audio_file)\n",
        "    return model.stt(buffer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cndBj7-E_oMg"
      },
      "source": [
        "####**get_mic() function: reaching the microphone from the colab platform and getting the audio**\n",
        "\n",
        "Since the microphone is unreachble from google colab, we resort to JavaScript in order to build this connection to the hardware and store the audio information in the form of a numpy array (buffer) and sample rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQg4P411kpnT"
      },
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKxDme-dt5Uz"
      },
      "source": [
        "def get_mic():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  rate, buffer = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return buffer, rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-vl6_E8AYRt"
      },
      "source": [
        "####**get_audio(): putting the microphone and the transcription functions on top of each other**\n",
        "\n",
        "This function activates the microphone, record its content and convert it into a .wav file, so it can get a transcript from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wCcK23oznh3"
      },
      "source": [
        "def get_audio():\n",
        "    buffer, rate = get_mic()\n",
        "    soundfile.write(\"/content/mic_result.wav\", data = buffer, samplerate = rate)\n",
        "\n",
        "    if rate != 16000:\n",
        "      audio, sr = librosa.load('/content/mic_result.wav', sr=16000)\n",
        "      soundfile.write(\"/content/mic_result.wav\", data = audio, samplerate = sr)\n",
        "    \n",
        "      transcript = get_transcript(\"/content/mic_result.wav\")\n",
        "\n",
        "      return transcript\n",
        "    \n",
        "    else:\n",
        "      transcript = get_transcript(\"/content/mic_result.wav\")\n",
        "    \n",
        "    return transcript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "bqxjgc67CKaJ",
        "outputId": "ba9b7f7c-10e8-441e-cec5-d45259cab338"
      },
      "source": [
        "get_audio()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is a very nice boy '"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liohu-dz_F0t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}